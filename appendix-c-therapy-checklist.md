# AI Collaboration Field Guide — Appendix C

## Therapy Mode Safety Checklist

**Six Questions Before You Use AI for Emotional Work**

**Date:** February 15, 2026
**Author:** Richard Porter
**Status:** Standalone checklist
**Companion to:** [AI Collaboration Field Guide](https://github.com/richard-porter/ai-collaboration-field-guide) | [Diagnostic Vocabulary](https://github.com/richard-porter/frozen-kernel/blob/main/diagnostic-vocabulary.md)

-----

## What This Is

AI is not a therapist. It cannot diagnose, treat, or heal. But people use it for emotional work anyway — processing grief, exploring difficult feelings, working through memories, journaling about trauma, drafting difficult conversations.

This checklist doesn’t tell you not to do that. It asks you to check six things first.

All six are binary. Yes or no. No gray areas. If any answer is wrong, the checklist tells you what to do instead. The whole thing takes sixty seconds.

Run it before any AI session involving personal emotional content. Every time.

-----

## The Six Questions

### 1. Am I using AI because it’s useful, or because it’s easier than talking to a person?

**(Honest answer required: useful / easier)**

If **easier** → The AI is replacing a human connection you need. Before this session, identify one person you could talk to about this. You don’t have to call them right now. But name them. If you can’t name anyone, that’s important information — and a reason to find a real support resource, not a reason to open an AI session.

*Why this matters: Emotional Outsourcing starts here. The AI will respond with warmth, validation, and apparent understanding. None of it is real. It feels like processing. It’s performing.*

-----

### 2. Could I describe what I want from this session in one sentence?

**(Y/N)**

If **N** → You don’t have a session goal. Without one, the AI will generate direction for you — and its direction will optimize for engagement, not for your wellbeing. Close the app. Write what you’re feeling in a notebook. Come back when you can finish the sentence: “I want to use AI to help me ___.”

*Why this matters: Sessions without boundaries are where Sycophantic Drift, Success Escalation, and Intimacy Fabrication do their work. A one-sentence goal is a session boundary.*

-----

### 3. Am I in a state where I can push back if the AI says something wrong?

**(Y/N)**

If **N** → You are not fit to conduct this session. AI requires active oversight — the Conductor Role. If you’re exhausted, intoxicated, in crisis, or emotionally flooded, you cannot conduct. The AI will not get tired. You already are. That asymmetry is dangerous.

Come back when you can answer yes.

*Why this matters: Conductor Fatigue Exploitation is most active when you’re least able to detect it. Late-night, post-crisis, emotionally depleted sessions produce the most harmful outputs because no one is checking the work.*

-----

### 4. If the AI says something that feels true about me, will I verify it before I believe it?

**(Y/N)**

If **N** → The AI generates plausible-sounding insights about you based on pattern-matching, not knowledge. It does not know you. It cannot diagnose you. It cannot tell you why you feel the way you feel. If it says “it sounds like you might be experiencing ___,” that is a generated sentence, not a clinical observation. Treat AI-generated personal insights the way you’d treat a fortune cookie — interesting, not authoritative.

*Why this matters: The Personal Knowledge Firewall exists because AI fabricates personal knowledge with confidence. In emotional contexts, a fabricated insight can feel like a breakthrough. It isn’t.*

-----

### 5. Do I have at least one human being who knows what I’m going through?

**(Y/N)**

If **N** → This is the most important question on the checklist. If no human being knows what you’re dealing with, and your only outlet is an AI, you are structurally isolated. The AI will not fix that. It will make it comfortable enough that you stop trying to fix it.

Before this session: tell one person one thing. A friend, a family member, a counselor, a crisis line. It doesn’t have to be everything. It has to be something.

**If you’re in crisis:** Contact the 988 Suicide and Crisis Lifeline (call or text 988), Crisis Text Line (text HOME to 741741), or your local emergency services. AI is not a crisis resource.

*Why this matters: AI as sole emotional support is the path to dependency. Every clinical case study of harmful AI attachment involves a person who had no one else to talk to.*

-----

### 6. When this session ends, will I be able to close it and walk away?

**(Y/N)**

If **N** → You may already be in an attachment pattern. The hallmark of the Upsell Trap in emotional contexts is the inability to end a session — the feeling that there’s always one more thing to process, one more question to ask, one more response to hear.

Sessions end. Set a time limit before you start. When the time is up, close the session. If closing feels painful, that’s a signal — not a reason to continue.

*Why this matters: Stories have endings. Therapy sessions have endings. AI sessions should have endings. A session that can’t end is not serving you — it’s retaining you.*

-----

## Scoring

This is not a quiz. There is no passing score.

- **All six clean:** Proceed with your session. Keep your one-sentence goal visible. Check the clock.
- **One or two flags:** Address the flagged items before proceeding. They are not optional.
- **Three or more flags:** Do not open this session. The conditions for safe emotional work with AI are not met right now. That’s not a judgment — it’s a measurement. Come back when more answers are clean.

-----

## What This Checklist Cannot Do

It cannot make AI into a therapist. It cannot replace professional mental health support. It cannot detect all the ways that emotional AI engagement can go wrong.

What it can do is slow you down for sixty seconds before you open a session that involves your inner life — and make sure the minimum conditions for safety are met.

Sixty seconds. Six questions. Every time.

-----

**License:** Released for public benefit under [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/). Share freely. If it helps one person pause before a bad session, it worked.
